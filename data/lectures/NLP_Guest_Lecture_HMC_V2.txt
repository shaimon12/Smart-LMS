Figurative Language Modelling for Health Mention Classification on Social Media
GUEST LECTURE – COMP8420
DR. USMAN NASEEM, USMAN.NASEEM@MQ.EDU.AU, SCHOOL OF COMPUTING
30-05-2025
Research Overview
My research aims to develop innovative representation learning 
techniques that aids machines to understand and generate human 
language at scale
Mining Online 
Health Information
Health Mention 
Classification
Mental Health 
Surveillance
Cyber Informatics
Hate Speeches
Abusive Content
Fake News & 
Propaganda
Rumour
Online Opinion & 
Sarcasm Mining
Sentiment 
Analysis
Irony & Sarcasm
Biomedical AI
Medical VQA
Biomedical NLP
Medical Dialogue 
Generation
Focus of 
today’s talk
Topic
Figurative Language Modelling for 
Health Mention Classification on Social Media
Figurative Language Modelling for 
Health Mention Classification on Social Media
What is Health Mention Classification (HMC)?
HMC aims to detect whether a text contains 
personal health mention or not.
In social media, people often use disease or 
symptom terms in ways other than to describe 
their health.
What is Figurative language?
Figurative language refers to words or phrases 
that are meaningful, but not literally true.
Social media platforms are a valuable source 
of information for public health surveillance.
Figurative Language Modelling for 
Health Mention Classification on Social Media
Problem & Motivation
– Human languages are messy, 
ambiguous, and ever-changing.
How can we model language?
How can we enable machines to understand human language like humans? 
Natural Language Processing
Language Modelling
– A Language Model (LM) captures the probability of a sequence of words in the language.
Train a Language Model
History
Pretrained (Large) Language Models
LLaMA
Bidirectional Encoder Representations from Transformers (BERT) 
Devlin et al., “Bert: Pre-training of deep bidirectional transformers for language understanding” ACL 2018
Limitations of BERT
a group of kids is called a migraine
Personal Health Mentions
Figurative Health Mentions
50 common health mention posts
probe
Practical Implications
introduce errors in NLP tools and lead to a flawed conclusion
over-represent the importance of certain health issues by location or over time 
and lead to poor quality decision-making about policy or resource allocation.
The use of figurative language is ubiquitous, may:
Goal: This project aims to develop new methods to improve text 
representation to identify figurative language in health mention 
classification task on social media. 
Challenges:
•
Lack of domain knowledge in existing language models
•
Require a large amount of labelled data
•
Not based on linguistic theories
•
lack the discrimination between the literal and figurative meaning of the target words
•
Not robust and transferable
Research Questions
How to encode knowledge into NLP language models, general or domain specific?
vs.
[Naseem et al. ACL2022*]
How to improve text representations to better capture semantic inconsistencies 
in figurative language based on linguistic theories?
[Naseem et al. WSDM 2024]
Figurative Language Modelling for Health Mention Classification on Social Media
Public availability: https://huggingface.co/publichealthsurveillance/PHS-BERT
[ACL2022*]
[WSDM 2024]
[IEEE TAI 2022]
[Webconf 2022 & IEEE TCSS 2022]
Project #1
Benchmarking for Public Health Surveillance tasks on Social Media with a 
Domain-Specific Pretrained Language Model
[ACL’ 2022*]
Encoding Domain Specific Knowledge
Encoding domain specific knowledge in language model Pretraining
Domain Specific Knowledge
Internalize
[Naseem et al. ACL2022*]
PHS-BERT
Encoding domain specific knowledge in language model Pretraining
Please refer to a paper for results on other tasks related to public health surveillance on social media.
For Demo: https://huggingface.co/spaces/publichealthsurveillance/PHS-BERT
Public availability: https://huggingface.co/publichealthsurveillance/PHS-BERT
https://nlp.johnsnowlabs.com/models?q=PHS-BERT
[Naseem et al. ACL2022*]
Discussion and Next Step
• lack the discrimination between the literal meaning and non-literal 
meaning of the target words
• Require a large amount of labelled data
• Not based on linguistic theories
• Not robust and transferable
Research Aims
• Develop a method that can discriminate 
between literal and figurative use of a 
disease or symptom words based on 
linguistic theories.
• How to improve the performance without 
relying on the large labelled data?
• Design a robust and transferable method.
Project #2
A Linguistic Grounding-Infused Contrastive Learning Approach for Health Mention 
Classification on Social Media
[WSDM’ 2024]
A Contrastive Language Model with Semi-supervised Learning
Contrastive Learning
• Contrastive learning is a type of machine learning approach that aims to learn useful 
representations of data by contrasting similar and dissimilar pairs of examples.
Contrastive Learning
Linguistic groundings
A linguistic theory (Pragglejaz Group, 2007) states that a word is 
identified as a figurative if the literal meaning of a word contrasts 
with the meaning that word adopts in this context.
I have a depression
Contrast between the literal and the figurative meaning serves as an 
important criterion for detecting figurative use of a target word.
Sushi cured my depression
Target word
depression
A Linguistic Grounding-Infused Contrastive Learning 
Approach for Health Mention Classification on Social Media
• Contrastive objective to model the 
semantic incongruence in figurative 
language based on linguistic theories
• Combines semi-supervised learning 
with self-training to alleviate the label 
scarcity issue
• Robust and transferable across the 
social media platforms
A Linguistic Grounding-Infused Contrastive Learning 
Approach for Health Mention Classification on Social Media
Stage 1
•
Pre-trained Model
•
Contrastive Objective
Metaphor Identification procedure: A word is identified as a metaphor if the literal meaning of a word contrasts with the meaning that word adopts in this context.
Stage 2
•
Semi-supervised Learning
•
Target-based Generating Approach
•
Self-Training (ST)
Target word: fever
A Linguistic Grounding-Infused Contrastive Learning 
Approach for Health Mention Classification on Social Media
Training Procedure:
Soft pseudo-labels
A Linguistic Grounding-Infused Contrastive Learning 
Approach for Health Mention Classification on Social Media
Overall Performance
Overall Performance (Figurative class only)
A Linguistic Grounding-Infused Contrastive Learning 
Approach for Health Mention Classification on Social Media
t-SNE embedding visualization
Robustness and Transferability
A Linguistic Grounding-Infused Contrastive Learning 
Approach for Health Mention Classification on Social Media
Discussion
•
Leveraged self-training and designs a simple but effective metaphor detection model 
based on the pre-trained backbone to capture the contextualized features.
•
Incorporated a contrastive objective into the model to capture the semantic 
incongruence and use a simple strategy to automatically construct substantial training 
data ready for self-training.
•
Experiments 
using 
publicly 
available 
health-mention 
datasets
collected from Twitter and Reddit and show that proposed method outperforms the 
state-of-the-art HMC methods on both datasets
•
Further, analysis in cross-domain and multi-domain settings showed that BEAST is 
generalizable and transferable
Other Research Interests
Modeling User Representation for Mental Health Assessment on Social Media
Temporal Modelling
Severity Identification
Modeling User Representation for Mental Health Assessment on Social Media
[Webconf 2022 & Webconf 2023]
[SNAM-2023]
Improved Text Representation for Sentiment Analysis, Irony & Sarcasm, Misinformation
[IJCNN 2021]
[Neural Networks 2022]
Financial news 
sentiment analysis
Vaccine sentiment analysis
[IJCNN 2020]
Irony and sarcasm detection
Misinformation detection
[WSDM 2024]
Sentiment Analysis
Irony and Sarcasm detection
Misinformation detection
User driven Learning for Personalised Recommender Systems
[ICDM* 2021]
[COLING 2022]
3
6
[Webconf 2023]
[ICDM* 2023]
Domain Specific Knowledge Learning for Medical and Healthcare
Medical VQA
[IEEE JBHI 2022]
Medical Dialogue Generation
[SIGIR 2023]
Medical VQA
[ACL* 2022]
Biomedical NLP
[IEEE JBHI 2023]
[IEEE SMC]
Modality-Aware Contextual Representation Learning for Memes Analysis
Modality-Aware Contextual Representation Learning for Memes Analysis
[WSDM 2023]
[Webconf 2023]
[Webconf 2024]
Fairness and Biasness Mitigation – Low Resource NLP
LLM – Misinformation, Disease Progression & RAG
[LLM – Misinformation Generation and Detection]
[LLM for Disease Progression]
[Domain specific LLM – LLM+RAG}
LLM - Dialogue Generation, Low Resource & Code-Mixed
[LLM for Low Resource Languages]
[LLM for Code-Mixed Languages]
LLM – Reasoning & Topic Modelling
[LLM for Reasoning]
[LLM for Topic Modeling]
@UsmanNaseem87
https://www.linkedin.com/in/usmannaseem87/
https://usmaann.github.io/
Thank you! 
Questions?
usman.naseem@mq.edu.au
Interested in MRes or PhD??
Scholarships Available for both 
Domestic & International Students