This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or has licence to 
use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Lecture 5 | Date: 28th March 2025 | Prof. Longbing Cao | Www.DataSciences.Org
COMP 8420 Advanced NLP
DEVELOPING LLMS - MULTIMODAL LLMS
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Agenda
OFFICE | FACULTY | DEPARTMENT
2
• Assignment 2
• Multimodal LLMs (MLLMs) overview
• MLLM architectures
• MLLM tasks
• MLLM applications
• Speech to text (text to speech)
• Image-to-text, text-to-image
• Visual question-answering
• Text-to-video
• Text-to-3D
• Vision-language to action
• Vision-language to emotion
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
References
OFFICE | FACULTY | DEPARTMENT
3
• Natural Language Processing with Transformers: Chapter 11
• Hands-on Large Language Models: Chapter 9
• wav2vec: an early success of speech-to-text modeling
• OpenAI’s open -source Whisper model
• Online resources/public domains
• The slides may involve materials from online, public domains, and other 
lectures etc., do not share the slides
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this 
material publicly online without permission. Macquarie University is the copyright owner of (or has licence to use) the intellectual property in 
this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLMs: Overview
OVERVIEW AND LANDSCAPE
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLM: Humanoid robotics and AI
OFFICE | FACULTY | DEPARTMENT
5
• Integrating comprehensive AI and emotion etc capabilities
-
Situated, embodied
-
Humane, emotional, 
personalized
-
Real-time
-
Interactive 
-
Multimodal, LMMs, LLMs
-
On-humanoid, edge and cloud
-
Vision, perception, action and 
emotion
-
Vision-to-action
-
Vision-to-language
-
Vision-to-language-to-emotion
L Cao. AI Robots and humanoid AI: Review, Perspectives, and 
Directions, 1-37, 2024.
https://www.youtube.com/watch?v=OUDPcn_7pts
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLM: Overview
OFFICE | FACULTY | DEPARTMENT
6
• Modalities: 
• Communication/in
teraction 
• Text: language
• Image: vision
• Audio/sound: 
speech
• Physical world
• Smell
• Touch
• Graph
• Space/map
• 3D
• …
https://mllm2024.github.io/CVPR2024/
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLM: Overview
OFFICE | FACULTY | DEPARTMENT
7
• MLLM: 
• Multimodal input
• Unimodal output
• Multimodal output
• Physical world
• Smell
• Touch
• Graph
• Space/map
• 3D
• …
Hands-on Large Language Models, Chapter 9
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLM: Overview
OFFICE | FACULTY | DEPARTMENT
8
• MLLM: 
• Input-perceiving 
MLLM
• Image-perceiving: 
GPT-4v
• Video-perceiving: 
Video-ChatGPT
• Audio-perceiving: 
AudioGPT
• 3D-perceiving: 
3D-GPT
• X-perceiving: 
BioGPT
• Perceiving + 
generating 
https://mllm2024.github.io/CVPR2024/
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLM: Overview
OFFICE | FACULTY | DEPARTMENT
9
• Multimodalities
• A fast-paced 
developing area in 
LLMs and GenAI
• Text/language
• Speech/audio
• Image/video
• Behaviors/actions 
https://arxiv.org/pdf/2408.01319v1
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this 
material publicly online without permission. Macquarie University is the copyright owner of (or has licence to use) the intellectual property in 
this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
LLMs: Architectures
FOUNDATIONS AND TRENDS
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Vision-Language Models
OFFICE | FACULTY | DEPARTMENT
11
• Vision-language 
models for visual 
recognition
• VLM
• VLP: vision-
language 
pretraining
• Contrastive 
objectives
• Generative 
objectives 
• Alignment 
objectives 
Vision-Language Models for Vision Tasks-A Survey
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Vision-Language Models
OFFICE | FACULTY | DEPARTMENT
12
• Vision-language models 
for visual recognition
• Supervised vision pre-
training, fine-tuning, and 
prediction
• Unsupervised vision 
pretraining, fine-tuning, 
and prediction
• Vision-language 
pretraining
• Vision-language zero-
shot prediction
Vision-Language Models for Vision Tasks-A Survey
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Diffusion model 
OFFICE | FACULTY | DEPARTMENT
13
• Diffusion models, diffusion 
probabilistic models, score-based 
generative models
•
Latent variable generative models
•
Forward, reverse and sampling 
•
Learn a diffusion process for given data, 
which can generate new elements 
distributed similar to the origin 
•
Diffusion: perform random walk with drift 
through all possible space
•
Different samplings for  efficiency and 
quality
•
Variational inference 
•
Backbone: denoising model, U-nets, 
Transformers
• Hybrid with other models 
•
Text-conditioned generation: text encoders, 
cross-attention
•
Stable Diffusion, DALL-E, Sora
Denoising Diffusion Probabilistic Models
Score-Based Generative Modeling through Stochastic Differential Equations
High-Resolution Image Synthesis with Latent Diffusion Models
Diffusion Models: A Comprehensive Survey of Methods and Applications
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Vision Transformers
OFFICE | FACULTY | DEPARTMENT
14
• Vision Transformer (ViT)
• Transformer to vision
• Convert image to 
patches of images (like 
tokens of text)
• Flatten input image
• Linear embedding of 
patches
• CNN to sequences of 
image patches
• Attention with CNN to 
cross attention for 
sequences  
Hands-on Large Language Model: Chapter 9
An Image is Worth 16x16 Words: Transformers for Image 
Recognition at Scale: https://arxiv.org/abs/2010.11929
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
CLIPs 
OFFICE | FACULTY | DEPARTMENT
15
• CLIP: Contrastive Language-Image Pre-
training
•
Foundational multimodal embedding 
model
•
Learn transferable visual models from 
natural language supervision
•
Learn directly from raw text about 
images
•
Pretraining of predicting which captions 
go with which images
• NLIP, SLIP, GLIP, etc.
Learning Transferable Visual Models From Natural Language Supervision
Hands-on Large Language Model: Chapter 9
from transformers import CLIPTokenizerFast, CLIPProcessor, 
CLIPModel 
model_id = "openai/clip-vit-base-patch32" 
# Load a tokenizer to preprocess the text 
clip_tokenizer = CLIPTokenizerFast.from_pretrained(model_id) 
# Load a processor to preprocess the images 
clip_processor = CLIPProcessor.from_pretrained(model_id) 
# Main model for generating text and image embeddings 
model = CLIPModel.from_pretrained(model_id)
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Visual BERTs & ViLBERT
OFFICE | FACULTY | DEPARTMENT
16
• VisualBERT
•
 model vision-language 
tasks
•
Align elements of input 
text with regions of 
associated input image 
by self-attention
• ViLBERT
•
Vision-and-Language 
BERT
•
Task-agnostic joint 
representations of 
image and language
•
Process visual and 
textual inputs in 
separate streams that 
interact through co-
attentional transformer 
layers
VisualBERT: A Simple and Performant Baseline for Vision and Language
ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-
and-Language Tasks
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
FLAVA 
OFFICE | FACULTY | DEPARTMENT
17
• FLAVA: foundational 
language and vision 
alignment
• Combine vision and 
language
• Joint pretraining on both 
unimodal and multimodal 
data
• Unpaired images, text
• Image-text pairs
• Cross-domain alignment 
objectives
• Multimodal fusion 
objectives 
FLAVA: A Foundational Language And Vision Alignment Model
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Multimodal chain of thought
OFFICE | FACULTY | DEPARTMENT
18
• Multimodal-CoT
• Involve text and image 
into a two-stage 
framework separates 
rationale generation 
and answer inference 
• CoT reasoning with 
LLMs
• Optimizing 
demonstrations
• Optimizing reasoning 
chains
• Eliciting CoT reasoning 
by fine-tuning models
Multimodal Chain-of-Thought Reasoning in Language Models
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Unified MLLM
OFFICE | FACULTY | DEPARTMENT
19
• Any-to-any MLLM
• NExT-GPT 
• Connect multimodal adaptors 
to diffusion decoders by LLM
NExT-GPT: Any-to-Any Multimodal LLM
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Multimodal fusion
OFFICE | FACULTY | DEPARTMENT
20
• Multimodal fusion
• Similarity
• Linear
• Multiplicative 
• Attention-based 
• Bilinear 
https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/sl
ides/Multimodal-Deep-Learning-CS224n-Kiela.pdf
Deep Multimodal Data Fusion
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Multimodal alignment and fusion
OFFICE | FACULTY | DEPARTMENT
21
• Multimodal fusion
• Encoder-decoder 
fusion
• Data fusion
• Feature fusion
• Output fusion
• Fusion methods
• Early fusion
• Intermediate fusion
• Late fusion
Multimodal Alignment and Fusion: A Survey
Deep Multimodal Data Fusion
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Multimodal alignment and fusion
OFFICE | FACULTY | DEPARTMENT
22
• Multimodal fusion
• Attention-based 
•
Attention-based 
connectors: align 
multimodal features and 
then feed to LLM
•
Attention-based adapters: 
feed unimodal features to 
LLMs
• Generative NN-based
• Graph NN-based
•
…
Multimodal Alignment and Fusion: A Survey
Deep Multimodal Data Fusion
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this 
material publicly online without permission. Macquarie University is the copyright owner of (or has licence to use) the intellectual property in 
this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLMs: Multimodal Tasks
TASKS AND APPLICATIONS
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Speech/audio to text
OFFICE | FACULTY | DEPARTMENT
24
• Speech to text:
•
Process speech/audio to predict its 
transcripts
•
Adult human hearing frequencies: 20 Hz 
– 20 kHz
•
By age 25: highest 17 kHz
•
Reproduce waveform by sampling 
twice the highest frequency, 40 
kHz
•
CD sample rate 44.1 kHz
•
wav2vec
•
OpenAI’s Whisper
•
16 kHz sample rate
•
680k hours of multilingual and 
multitask supervision 
•
Cannot decode dolphin talk (200 
Hz – 30 kHz)
https://learning.oreilly.com/library/view/natural-language-processing: Chapter 11
https://github.com/openai/whisper
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Image to text
OFFICE | FACULTY | DEPARTMENT
25
• Image to text: caption
• Visual-semantic 
embeddings
• Visual-semantic 
alignment
• Attention as visual-
semantic alignment
Show, Attend and Tell: Neural Image Caption Generation with Visual Attention: 
https://arxiv.org/abs/1502.03044
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Visual question-answering (VQA)
OFFICE | FACULTY | DEPARTMENT
26
• Visual question-
answering
• Vision language 
models
• Integrating computer 
vison with NLP
• Generate answers to 
questions on visual 
input
• Early: feature 
extraction and fusion
• Now: vision language 
pretraining (VLP)
From image to language: A critical analysis of Visual Question Answering (VQA) approaches, challenges, and opportunities
Visual Question Answering: A Survey on Techniques and Common Trends in Recent Literature
A Comprehensive Survey on Visual Question Answering Datasets and Algorithms
Fig. 5 Overview of traditional pre-transformer VQA 
architecture using joint embedding and attention, with 
CNN-RNN encoder pairs, multimodal fusion, and 
classification head.
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Text to image
OFFICE | FACULTY | DEPARTMENT
27
• Text to image: conditional image 
synthesis
• DALL∙E 3/OpenArt AI
• Turn imagination to imagery
• Built on ChatGPT
• Text to image generation
• Prompting to tailored, detailed, 
personalised, polished images
• Noisy and inaccurate image 
captions in the training dataset
• Train a bespoke image captioner, 
then recaption the training dataset
• Train several text-to-image models 
for synthetic captions reliably 
improving prompt following ability
• Address prompt following, 
coherence, and aesthetics
https://cdn.openai.com/papers/dall-e-3.pdf
Before login
After login
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Text to video
OFFICE | FACULTY | DEPARTMENT
28
• Text to video: 
•
Understand and simulate 
physical world in motion
•
Problems with real-world 
interactions
•
Visual quality
•
Adherence to user’s prompt
• Sora
•
Text-to-video generation model
•
Generate complex scenes with 
multiple characters, specific 
types of motion, and accurate 
details of the subject and 
background
•
Understands not only what the 
user has asked for in the prompt, 
but also how those things exist in 
the physical world
https://openai.com/sora/
https://openai.com/index/sora/
Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Text to 3D
OFFICE | FACULTY | DEPARTMENT
29
• Text to 3D: text-
conditional 3D object 
generation
• Text-to-image diffusion 
model
• Produce a 3D point cloud 
by another diffusion 
model, conditional on the 
generated image
Point-E: A System for Generating 3D Point Clouds from Complex 
Prompts: https://arxiv.org/abs/2212.08751
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Vision-language to action
OFFICE | FACULTY | DEPARTMENT
30
https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/
• Robotic Transformer 2 (RT-2) 
• Vision-language-action model
• VLM on web-scale data and robotics data
• Transfer knowledge to robotic instructions for robot control 
• Robot learning from multitask demonstrations
• CoT for multi-stage semantic reasoning
• Generalisation capabilities and semantic and visual 
understanding
https://youtu.be/F3xCTq15mQM
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Vision-language to emotion
OFFICE | FACULTY | DEPARTMENT
31
• Vision-language to 
emotion (VLE)
• Computer vision + NLP/LLMs 
+ emotion learning
• Facial expression  vision 
and language input
• Cross-modal interaction
• Multi-party conversation
UGotMe: An Embodied System for Affective Human-Robot Interaction
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this 
material publicly online without permission. Macquarie University is the copyright owner of (or has licence to use) the intellectual property in 
this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLMs: Applications
APPLICATIONS AND ISSUES
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLM opportunities
OFFICE | FACULTY | DEPARTMENT
33
• Gemini:
• Prompted with images, text, 
codes, video
• Gemini on Vertex AI
• Use prompts to extract text from 
images, convert image text to 
JSON, generate answers about 
uploaded images
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLM opportunities
OFFICE | FACULTY | DEPARTMENT
34
• GPT applications: 
• Foundation models 
of GPT, etc LLMs
• Multimodal tasks
• Multimodal inputs
• Multimodal outputs
• Multimodal 
applications
https://chatgpt.com/gpts
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this 
material publicly online without permission. Macquarie University is the copyright owner of (or has licence to use) the intellectual property in 
this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Take-home Messages
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
MLLMs dominate GenAI and 
applications
OFFICE | FACULTY | DEPARTMENT
36
• Vision and language, and other modalities, are increasingly 
dependent in AI, learning and analytics
• Approach the way physical world works
• Fast-paced developments and applications
• Significant challenges and gaps remain
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this material publicly online without permission. Macquarie University is the copyright owner of (or 
has licence to use) the intellectual property in this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Next week – Week 6
OFFICE | FACULTY | DEPARTMENT
37
•Developing LLMs 
•LLMs training and fine-tuning techniques
Week 12: Ameca – Our AI humanoid robot can automate 
efficient Communications, CRM, Operations, …
• Original Ameca
• Humanoid
• 32 degrees of freedom - 
emotion
• Conversation – ChatGPT
• MQ’s Ameca
• Integrating X-AI paradigms 
and multimodal 
capabilities 
•
Vision, conversation, visual 
conversation, action, 
language/text 
•
Emotion, sentiment
•
Multimodal recognition, 
imitation, classification, 
conversation, 
• Integrating DecentralisedAI
• AI4Tech
L Cao. AI Robots and Humanoid AI: Review, Perspectives and Directions, https://arxiv.org/abs/2405.15775, 1-37, 2024.
This material is provided to you as a Macquarie University student for your individual research and study purposes only. You cannot share this 
material publicly online without permission. Macquarie University is the copyright owner of (or has licence to use) the intellectual property in 
this material. Legal and/or disciplinary actions may be taken if this material is shared without the University’s written permission.
Question & Answer