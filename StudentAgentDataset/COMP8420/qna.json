[
  {
    "question": "What is a foundation model in NLP?",
    "answer": "A foundation model is a large pre-trained model trained on massive datasets, serving as the base for fine-tuning on specific NLP tasks."
  },
  {
    "question": "What are examples of foundation models?",
    "answer": "Examples include GPT-3.5, Claude, PaLM, BERT, LLaMA, and Mistral."
  },
  {
    "question": "What does fine-tuning mean in the context of LLMs?",
    "answer": "Fine-tuning is the process of continuing training on a pre-trained model using a smaller, task-specific dataset."
  },
  {
    "question": "What is the difference between prompt tuning and fine-tuning?",
    "answer": "Prompt tuning adjusts input formatting without altering the model, while fine-tuning retrains the model on new data."
  },
  {
    "question": "What was covered in Week 6 of COMP8420?",
    "answer": "Week 6 focused on fine-tuning large language models, covering parameter-efficient fine-tuning and adapter-based methods."
  },
  {
    "question": "When is the COMP8420 project presentation due?",
    "answer": "The presentation is scheduled for Week 13, Friday, June 6th, 2025."
  },
  {
    "question": "What is the final deadline for Assignment 3?",
    "answer": "Assignment 3 (code + report) is due during the exam period on June 17th, 2025."
  },
  {
    "question": "What type of model should we use for our project?",
    "answer": "You can use OpenAI\u2019s GPT-3.5 or open-source models like LLaMA2 or Mistral, depending on your goals and data."
  },
  {
    "question": "How do we evaluate our NLP project?",
    "answer": "Use metrics like BLEU, ROUGE, accuracy, and ablation studies to compare performance against baselines or alternatives."
  },
  {
    "question": "What are embedding models used for?",
    "answer": "They convert text into vector form for similarity search and retrieval, commonly used in RAG pipelines."
  },
  {
    "question": "How do we retrieve answers in a RAG system?",
    "answer": "Text chunks are embedded into vectors and searched via similarity to retrieve relevant content for generation."
  },
  {
    "question": "How are lectures delivered in COMP8420?",
    "answer": "Lectures are delivered via PDFs and practical notebooks, combining theory and hands-on exercises."
  },
  {
    "question": "What technologies are used in this course?",
    "answer": "Hugging Face, PyTorch, LangChain, OpenAI APIs, and vector databases like FAISS."
  },
  {
    "question": "Can we use ChatGPT in our project?",
    "answer": "Yes, but your project must demonstrate additional engineering beyond just using the API."
  },
  {
    "question": "What is parameter-efficient fine-tuning?",
    "answer": "It refers to fine-tuning techniques like LoRA and Adapters that update only a small subset of the model."
  },
  {
    "question": "What should we cover in the presentation?",
    "answer": "Your project title, real-world problem, methodology, expected outcome, and team contributions."
  },
  {
    "question": "What\u2019s the length of the presentation?",
    "answer": "You must present for 3\u20134 minutes during the Week 13 Practice Workshop."
  },
  {
    "question": "How can we improve our mark?",
    "answer": "Make your project novel, apply evaluation methods, and clearly explain your work in the report and presentation."
  },
  {
    "question": "What are some real-world NLP tasks?",
    "answer": "Text classification, summarization, question answering, entity recognition, translation, and dialogue generation."
  },
  {
    "question": "Can we build an agent using LangChain?",
    "answer": "Yes, LangChain is commonly used to implement RAG-based agents using LLMs and vector stores."
  }
]